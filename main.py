import torch
import torch.nn as nn
w_t_i = {'\t': 0, ' ': 1, '!': 2, '"': 3, '#': 4, '$': 5, '%': 6, '(': 7, ')': 8, '*': 9, '+': 10, ',': 11, '-': 12, '.': 13, '/': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, ';': 26, '=': 27, '>': 28, '?': 29, 'A': 30, 'B': 31, 'C': 32, 'D': 33, 'E': 34, 'F': 35, 'G': 36, 'H': 37, 'I': 38, 'J': 39, 'K': 40, 'L': 41, 'M': 42, 'N': 43, 'O': 44, 'P': 45, 'Q': 46, 'R': 47, 'S': 48, 'T': 49, 'U': 50, 'V': 51, 'W': 52, 'X': 53, 'Y': 54, 'Z': 55, '[': 56, ']': 57, '_': 58, 'a': 59, 'b': 60, 'c': 61, 'd': 62, 'e': 63, 'f': 64, 'g': 65, 'h': 66, 'i': 67, 'j': 68, 'k': 69, 'l': 70, 'm': 71, 'n': 72, 'o': 73, 'p': 74, 'q': 75, 'r': 76, 's': 77, 't': 78, 'u': 79, 'v': 80, 'w': 81, 'x': 82, 'y': 83, 'z': 84, 'Â«': 85, 'Â°': 86, 'Â»': 87, 'Ã': 88, 'Ã‰': 89, 'Ã': 90, 'Ã“': 91, 'Ã–': 92, 'Ãš': 93, 'Ãœ': 94, 'Ã ': 95, 'Ã¡': 96, 'Ã¢': 97, 'Ã¤': 98, 'Ã§': 99, 'Ã¨': 100, 'Ã©': 101, 'Ãª': 102, 'Ã­': 103, 'Ã®': 104, 'Ã¯': 105, 'Ã³': 106, 'Ã´': 107, 'Ã¶': 108, 'Ã¹': 109, 'Ãº': 110, 'Ã¼': 111, 'Ã½': 112, 'Å': 113, 'Å‘': 114, 'Å“': 115, 'Å°': 116, 'Å±': 117, 'Ì': 118, 'Ğ': 119, 'Ğ': 120, 'Ğ‘': 121, 'Ğ’': 122, 'Ğ“': 123, 'Ğ”': 124, 'Ğ•': 125, 'Ğ–': 126, 'Ğ—': 127, 'Ğ˜': 128, 'Ğ™': 129, 'Ğš': 130, 'Ğ›': 131, 'Ğœ': 132, 'Ğ': 133, 'Ğ': 134, 'ĞŸ': 135, 'Ğ ': 136, 'Ğ¡': 137, 'Ğ¢': 138, 'Ğ£': 139, 'Ğ¤': 140, 'Ğ¥': 141, 'Ğ¦': 142, 'Ğ§': 143, 'Ğ¨': 144, 'Ğ©': 145, 'Ğ«': 146, 'Ğ¬': 147, 'Ğ­': 148, 'Ğ®': 149, 'Ğ¯': 150, 'Ğ°': 151, 'Ğ±': 152, 'Ğ²': 153, 'Ğ³': 154, 'Ğ´': 155, 'Ğµ': 156, 'Ğ¶': 157, 'Ğ·': 158, 'Ğ¸': 159, 'Ğ¹': 160, 'Ğº': 161, 'Ğ»': 162, 'Ğ¼': 163, 'Ğ½': 164, 'Ğ¾': 165, 'Ğ¿': 166, 'Ñ€': 167, 'Ñ': 168, 'Ñ‚': 169, 'Ñƒ': 170, 'Ñ„': 1171, 'Ñ…': 172, 'Ñ†': 173, 'Ñ‡': 174, 'Ñˆ': 175, 'Ñ‰': 176, 'ÑŠ': 177, 'Ñ‹': 178, 'ÑŒ': 179, 'Ñ': 180, 'Ñ': 181, 'Ñ': 182, 'Ñ‘': 183, '\u200b': 184, 'â€‘': 185, 'â€“': 186, 'â€”': 187, 'â€˜': 188, 'â€™': 189, 'â€œ': 190, 'â€': 191, 'â€': 192, 'â€¢': 193, 'â€¦': 194, 'â„¢': 195, 'â†': 196, 'â†’': 197, 'âš ': 198, 'âš¡': 199, 'âœ…': 200, 'åˆ©': 201, 'é¡º': 202, 'ï¸': 203, 'ğŸ†“': 204, 'ğŸ‡·': 205, 'ğŸ‡º': 206, 'ğŸŒ': 207, 'ğŸ¯': 208, 'ğŸ†': 209, 'ğŸ’¡ ğŸ’¡': 210, 'ğŸ’°': 211, 'ğŸ“Š': 212, 'ğŸ“': 213, 'ğŸ“': 214, 'ğŸ“': 215, 'ğŸ“±': 216, 'ğŸ“²': 217, 'ğŸ”„': 218, 'ğŸ”': 219, 'ğŸ”“': 220, 'ğŸ”§': 221, 'ğŸš€': 222, 'ğŸš¨': 223, 'ğŸ› ': 224, 'ğŸ›¡': 225, 'ğŸ¤”': 226, 'ğŸ¥‡': 227, 'ğŸ¥ˆ': 228, 'ğŸ¥‰': 229}
i_t_w = {0: '\t', 1: ' ', 2: '!', 3: '"', 4: '#', 5: '$', 6: '%', 7: '(', 8: ')', 9: '*', 10: '+', 11: ',', 12: '-', 13: '.', 14: '/', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: ';', 27: '=', 28: '>', 29: '?', 30: 'A', 31: 'B', 32: 'C', 33: 'D', 34: 'E', 35: 'F', 36: 'G', 37: 'H', 38: 'I', 39: 'J', 40: 'K', 41: 'L', 42: 'M', 43: 'N', 44: 'O', 45: 'P', 46: 'Q', 47: 'R', 48: 'S', 49: 'T', 50: 'U', 51: 'V', 52: 'W', 53: 'X', 54: 'Y', 55: 'Z', 56: '[', 57: ']', 58: '_', 59: 'a', 60: 'b', 61: 'c', 62: 'd', 63: 'e', 64: 'f', 65: 'g', 66: 'h', 67: 'i', 68: 'j', 69: 'k', 70: 'l', 71: 'm', 72: 'n', 73: 'o', 74: 'p', 75: 'q', 76: 'r', 77: 's', 78: 't', 79: 'u', 80: 'v', 81: 'w', 82: 'x', 83: 'y', 84: 'z', 85: 'Â«', 86: 'Â°', 87: 'Â»', 88: 'Ã', 89: 'Ã‰', 90: 'Ã', 91: 'Ã“', 92: 'Ã–', 93: 'Ãš', 94: 'Ãœ', 95: 'Ã ', 96: 'Ã¡', 97: 'Ã¢', 98: 'Ã¤', 99: 'Ã§', 100: 'Ã¨', 101: 'Ã©', 102: 'Ãª', 103: 'Ã­', 104: 'Ã®', 105: 'Ã¯', 106: 'Ã³', 107: 'Ã´', 108: 'Ã¶', 109: 'Ã¹', 110: 'Ãº', 111: 'Ã¼', 112: 'Ã½', 113: 'Å', 114: 'Å‘', 115: 'Å“', 116: 'Å°', 117: 'Å±', 118: 'Ì', 119: 'Ğ', 120: 'Ğ', 121: 'Ğ‘', 122: 'Ğ’', 123: 'Ğ“', 124: 'Ğ”', 125: 'Ğ•', 126: 'Ğ–', 127: 'Ğ—', 128: 'Ğ˜', 129: 'Ğ™', 130: 'Ğš', 131: 'Ğ›', 132: 'Ğœ', 133: 'Ğ', 134: 'Ğ', 135: 'ĞŸ', 136: 'Ğ ', 137: 'Ğ¡', 138: 'Ğ¢', 139: 'Ğ£', 140: 'Ğ¤', 141: 'Ğ¥', 142: 'Ğ¦', 143: 'Ğ§', 144: 'Ğ¨', 145: 'Ğ©', 146: 'Ğ«', 147: 'Ğ¬', 148: 'Ğ­', 149: 'Ğ®', 150: 'Ğ¯', 151: 'Ğ°', 152: 'Ğ±', 153: 'Ğ²', 154: 'Ğ³', 155: 'Ğ´', 156: 'Ğµ', 157: 'Ğ¶', 158: 'Ğ·', 159: 'Ğ¸', 160: 'Ğ¹', 161: 'Ğº', 162: 'Ğ»', 163: 'Ğ¼', 164: 'Ğ½', 165: 'Ğ¾', 166: 'Ğ¿', 167: 'Ñ€', 168: 'Ñ', 169: 'Ñ‚', 170: 'Ñƒ', 171: 'Ñ„', 172: 'Ñ…', 173: 'Ñ†', 174: 'Ñ‡', 175: 'Ñˆ', 176: 'Ñ‰', 177: 'ÑŠ', 178: 'Ñ‹', 179: 'ÑŒ', 180: 'Ñ', 181: 'Ñ', 182: 'Ñ', 183: 'Ñ‘', 184: '\u200b', 185: 'â€‘', 186: 'â€“', 187: 'â€”', 188: 'â€˜', 189: 'â€™', 190: 'â€œ', 191: 'â€', 192: 'â€', 193: 'â€¢', 194: 'â€¦', 195: 'â„¢', 196: 'â†', 197: 'â†’', 198: 'âš ', 199: 'âš¡', 200: 'âœ…', 201: 'åˆ©', 202: 'é¡º', 203: 'ï¸', 204: 'ğŸ†“', 205: 'ğŸ‡·', 206: 'ğŸ‡º', 207: 'ğŸŒ', 208: 'ğŸ¯', 209: 'ğŸ†', 210: 'ğŸ’¡', 211: 'ğŸ’°', 212: 'ğŸ“Š', 213: 'ğŸ“', 214: 'ğŸ“', 215: 'ğŸ“', 216: 'ğŸ“±', 217: 'ğŸ“²', 218: 'ğŸ”„', 219: 'ğŸ”', 220: 'ğŸ”“', 221: 'ğŸ”§', 222: 'ğŸš€', 223: 'ğŸš¨', 224: 'ğŸ› ', 225: 'ğŸ›¡', 226: 'ğŸ¤”', 227: 'ğŸ¥‡', 228: 'ğŸ¥ˆ', 229: 'ğŸ¥‰'}
class AI(nn.Module):
    def __init__(self):
        super().__init__()
        self.embai = nn.Embedding(173, 1028)
        self.lsai = nn.LSTM(1028, 2056, batch_first=True, dropout=0.4, num_layers=3)
        self.linai = nn.Linear(2056, 230)

    def forward(self, x):
        x = self.embai(x)
        if x.dim() == 2:
            x = x.unsqueeze(1)
        x, _ = self.lsai(x)
        x = x[:, -1, :]
        x = self.linai(x)
        return x

model = AI()
model.load_state_dict(torch.load('C:/Users/name/Downloads/pytorch_model.pth'))
model.eval()

while True:
 
    a = input("Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ (Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 40 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²): ").strip()
    
    if len(a) < 40:
        print("ĞÑƒĞ¶Ğ½Ğ¾ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 40 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²!")
        continue
    

    txt = a[-40:]
    print(f"ĞĞ°Ñ‡Ğ°Ğ»Ğ¾: '{txt}'")

    for i in range(100):
        try:
            input_indices = [w_t_i[ch] for ch in txt[-40:]]
        except KeyError as e:
            print(f"Ğ¡Ğ¸Ğ¼Ğ²Ğ¾Ğ» '{e}' Ğ½ĞµÑ‚ Ğ² ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ğµ. ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°.")
            break
        
        tnsr = torch.tensor([input_indices], dtype=torch.long)
        
        with torch.no_grad():
            output = model(tnsr) 
            if output.dim() == 3:
                logits = output[0, -1, :] 
            else:
                logits = output[0]
            probs = torch.softmax(logits, dim=-1)
            
            try:
                next_idx = torch.multinomial(probs, num_samples=1).item()
            except:
                next_idx = torch.argmax(probs).item()
            next_char = i_t_w[next_idx]
            txt += next_char
    
    print(f"\nĞ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ ({len(txt)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²):")
    print(txt)
    print("-" * 50)
